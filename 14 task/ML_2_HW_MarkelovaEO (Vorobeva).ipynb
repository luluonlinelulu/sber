{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "results_regression = pd.DataFrame(columns = ['model', 'task', 'R2'])\n",
    "results_classification = pd.DataFrame(columns = ['model', 'task', 'f1', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('boston.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%, предварительно выделив целевую переменную (колонка 'MEDV')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: (404, 13), тестовая выборка: (102, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Выделение целевой переменной\n",
    "target = data['MEDV']\n",
    "\n",
    "# Разделение данных на обуч. и тест. выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['MEDV'], axis=1), target, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Обучающая выборка: {X_train.shape}, тестовая выборка: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (404, 13) (404,)\n",
      "Testing dataset: (102, 13) (102,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Выделение целевой переменной\n",
    "y = data['MEDV']\n",
    "\n",
    "# Остальные колонки считаем признаковыми\n",
    "X = data.drop(['MEDV'], axis=1)\n",
    "\n",
    "# Разделение данных на обуч. и тест. выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training dataset:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing dataset:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso с параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 линейной регрессии: 0.6685\n",
      "R2 регрессии с Ridge: 0.6660\n",
      "R2 регрессии с Lasso: 0.6669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Обучение моделей\n",
    "lr = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "\n",
    "# Обучение моделей на обучающей выборке\n",
    "lr.fit(X_train, y_train)\n",
    "ridge.fit(X_train, y_train)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Вычисление R2 на тестовой выборке\n",
    "lr_r2 = r2_score(y_test, lr.predict(X_test))\n",
    "ridge_r2 = r2_score(y_test, ridge.predict(X_test))\n",
    "lasso_r2 = r2_score(y_test, lasso.predict(X_test))\n",
    "\n",
    "print(f\"R2 линейной регрессии: {lr_r2:.4f}\")\n",
    "print(f\"R2 регрессии с Ridge: {ridge_r2:.4f}\")\n",
    "print(f\"R2 регрессии с Lasso: {lasso_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Линейная регрессия: 0.6684825753971593\n",
      "Ridge регрессия: 0.6659608075261694\n",
      "Lasso регрессия: 0.6668687223368213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Обучение линейной регр.\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Обучение Ridge регр.\n",
    "rid_reg = Ridge()\n",
    "rid_reg.fit(X_train, y_train)\n",
    "\n",
    "# Обучение Lasso регр.\n",
    "las_reg = Lasso()\n",
    "las_reg.fit(X_train, y_train)\n",
    "\n",
    "# Вычисление R2 для каждой модели на тестовой выборке\n",
    "linear_r2 = r2_score(y_test, lin_reg.predict(X_test))\n",
    "ridge_r2 = r2_score(y_test, rid_reg.predict(X_test))\n",
    "lasso_r2 = r2_score(y_test, las_reg.predict(X_test))\n",
    "\n",
    "print(\"Линейная регрессия:\", linear_r2)\n",
    "print(\"Ridge регрессия:\", ridge_r2)\n",
    "print(\"Lasso регрессия:\", lasso_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации двумя способами 1) GridSearchCV, 2) RidgeCV и LassoCV, в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по всем моделям и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge регрессия (GridSearchCV): 0.6684825680074257\n",
      "Ridge регрессия (RidgeCV): 0.6684745342323266\n",
      "Lasso регрессия (GridSearchCV): 0.6684829595885678\n",
      "Lasso регрессия (LassoCV): 0.6684829595885678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Подбор параметров для Ridge регр. с помощью GridSearchCV\n",
    "param_grid = {'alpha': np.logspace(-5, 5, 11)}\n",
    "ridge_cv = GridSearchCV(Ridge(), param_grid, cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "ridge_best_model = ridge_cv.best_estimator_\n",
    "ridge_r2 = r2_score(y_test, ridge_best_model.predict(X_test))\n",
    "print(\"Ridge регрессия (GridSearchCV):\", ridge_r2)\n",
    "\n",
    "# Подбор параметров для Ridge регр. с помощью RidgeCV\n",
    "ridge_cv_mod = RidgeCV(alphas=np.logspace(-5, 5, 11))\n",
    "ridge_cv_mod.fit(X_train, y_train)\n",
    "ridge_r2_cv = r2_score(y_test, ridge_cv_mod.predict(X_test))\n",
    "print(\"Ridge регрессия (RidgeCV):\", ridge_r2_cv)\n",
    "\n",
    "# Подбор параметров для Lasso регр. с помощью GridSearchCV\n",
    "param_grid = {'alpha': np.logspace(-5, 5, 11)}\n",
    "lasso_cv = GridSearchCV(Lasso(), param_grid, cv=5)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "lasso_best_model = lasso_cv.best_estimator_\n",
    "lasso_r2 = r2_score(y_test, lasso_best_model.predict(X_test))\n",
    "print(\"Lasso регрессия (GridSearchCV):\", lasso_r2)\n",
    "\n",
    "# Подбор параметров для Lasso регр. с помощью LassoCV\n",
    "lasso_cv_mod = LassoCV(alphas=np.logspace(-5, 5, 11))\n",
    "lasso_cv_mod.fit(X_train, y_train)\n",
    "lasso_r2_cv = r2_score(y_test, lasso_cv_mod.predict(X_test))\n",
    "print(\"Lasso регрессия (LassoCV):\", lasso_r2_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки (используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 стандартной регрессии (с масштабированием): 0.6682\n",
      "R2 стандартной регрессии (с масштабированием MinMaxScaler): 0.6762\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Подготовка стандартных моделей\n",
    "standard_pipe = make_pipeline(StandardScaler(), Ridge())\n",
    "minmax_pipe = make_pipeline(MinMaxScaler(), Ridge())\n",
    "\n",
    "# Обучение моделей\n",
    "standard_pipe.fit(X_train, y_train)\n",
    "minmax_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Вычисление R2 на тестовой выборке\n",
    "standard_r2 = r2_score(y_test, standard_pipe.predict(X_test))\n",
    "minmax_r2 = r2_score(y_test, minmax_pipe.predict(X_test))\n",
    "\n",
    "print(f\"R2 стандартной регрессии (с масштабированием): {standard_r2:.4f}\")\n",
    "print(f\"R2 стандартной регрессии (с масштабированием MinMaxScaler): {minmax_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Линейная регрессия: -4148.942930338001 | Линейная регрессия (масштаб): 0.6684825753971608\n",
      "Ridge регрессия: -3726.3240267139986 | Ridge регрессия (масштаб): 0.668190107677443\n",
      "Lasso регрессия: -215.0515595121212 | Lasso регрессия (масштаб): 0.6240447523478461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Lasso was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Обучение моделей с различными методами масштабирования\n",
    "lin_reg = LinearRegression()\n",
    "ridge_reg = Ridge()\n",
    "lasso_reg = Lasso()\n",
    "\n",
    "# Обучение StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Создание pipelines\n",
    "lin_reg_scaled = make_pipeline(scaler, lin_reg)\n",
    "ridge_reg_scaled = make_pipeline(scaler, ridge_reg)\n",
    "lasso_reg_scaled = make_pipeline(scaler, lasso_reg)\n",
    "\n",
    "# Обучение моделей\n",
    "lin_reg_scaled.fit(X_train, y_train)\n",
    "ridge_reg_scaled.fit(X_train, y_train)\n",
    "lasso_reg_scaled.fit(X_train, y_train)\n",
    "\n",
    "# Вычисление R2 для каждой модели на тестовой выборке\n",
    "linear_r2 = r2_score(y_test, lin_reg.predict(X_test))\n",
    "linear_r2_scaled = r2_score(y_test, lin_reg_scaled.predict(X_test))\n",
    "\n",
    "ridge_r2 = r2_score(y_test, ridge_reg.predict(X_test))\n",
    "ridge_r2_scaled = r2_score(y_test, ridge_reg_scaled.predict(X_test))\n",
    "\n",
    "lasso_r2 = r2_score(y_test, lasso_reg.predict(X_test))\n",
    "lasso_r2_scaled = r2_score(y_test, lasso_reg_scaled.predict(X_test))\n",
    "\n",
    "print(\"Линейная регрессия:\", linear_r2, \"| Линейная регрессия (масштаб):\", linear_r2_scaled)\n",
    "print(\"Ridge регрессия:\", ridge_r2, \"| Ridge регрессия (масштаб):\", ridge_r2_scaled)\n",
    "print(\"Lasso регрессия:\", lasso_r2, \"| Lasso регрессия (масштаб):\", lasso_r2_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Линейная регрессия: -4148.942930338001 | Линейная регрессия (масштаб): 0.6684825753971608\n",
      "Ridge регрессия: -3726.3240267139986 | Ridge регрессия (масштаб): 0.668190107677443\n",
      "Lasso регрессия: -215.0515595121212 | Lasso регрессия (масштаб): 0.6240447523478461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Lasso was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Обучение моделей с различными методами масштабирования\n",
    "lin_reg = LinearRegression()\n",
    "ridge_reg = Ridge()\n",
    "lasso_reg = Lasso()\n",
    "\n",
    "# Обучение StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Создание pipelines\n",
    "lin_reg_scaled = make_pipeline(scaler, lin_reg)\n",
    "ridge_reg_scaled = make_pipeline(scaler, ridge_reg)\n",
    "lasso_reg_scaled = make_pipeline(scaler, lasso_reg)\n",
    "\n",
    "# Обучение моделей\n",
    "lin_reg_scaled.fit(X_train, y_train)\n",
    "ridge_reg_scaled.fit(X_train, y_train)\n",
    "lasso_reg_scaled.fit(X_train, y_train)\n",
    "\n",
    "# Вычисление R2 для каждой модели на тестовой выборке\n",
    "linear_r2 = r2_score(y_test, lin_reg.predict(X_test))\n",
    "linear_r2_scaled = r2_score(y_test, lin_reg_scaled.predict(X_test))\n",
    "\n",
    "ridge_r2 = r2_score(y_test, ridge_reg.predict(X_test))\n",
    "ridge_r2_scaled = r2_score(y_test, ridge_reg_scaled.predict(X_test))\n",
    "\n",
    "lasso_r2 = r2_score(y_test, lasso_reg.predict(X_test))\n",
    "lasso_r2_scaled = r2_score(y_test, lasso_reg_scaled.predict(X_test))\n",
    "\n",
    "print(\"Линейная регрессия:\", linear_r2, \"| Линейная регрессия (масштаб):\", linear_r2_scaled)\n",
    "print(\"Ridge регрессия:\", ridge_r2, \"| Ridge регрессия (масштаб):\", ridge_r2_scaled)\n",
    "print(\"Lasso регрессия:\", lasso_r2, \"| Lasso регрессия (масштаб):\", lasso_r2_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 стандартной регрессии (с масштабированием и полиномиальными признаками): 0.8171\n",
      "R2 стандартной регрессии (с масштабированием MinMaxScaler и полиномиальными признаками): 0.8299\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Подготовка стандартных моделей\n",
    "standard_pipe = make_pipeline(StandardScaler(), PolynomialFeatures(degree=2), Ridge())\n",
    "minmax_pipe = make_pipeline(MinMaxScaler(), PolynomialFeatures(degree=2), Ridge())\n",
    "\n",
    "# Обучение моделей\n",
    "standard_pipe.fit(X_train, y_train)\n",
    "minmax_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Вычисление R2 на тестовой выборке\n",
    "standard_r2 = r2_score(y_test, standard_pipe.predict(X_test))\n",
    "minmax_r2 = r2_score(y_test, minmax_pipe.predict(X_test))\n",
    "\n",
    "\n",
    "print(f\"R2 стандартной регрессии (с масштабированием и полиномиальными признаками): {standard_r2:.4f}\")\n",
    "print(f\"R2 стандартной регрессии (с масштабированием MinMaxScaler и полиномиальными признаками): {minmax_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, добавив PolynomialFeatures, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (без Poly): R^2 = 0.995880282578042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+03, tolerance: 4.272e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso (без Poly): R^2 = 0.9359910763646421\n",
      "Ridge (с Poly): R^2 = 0.9958802825780452\n",
      "Lasso (с Poly): R^2 = 0.9359910763646421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+03, tolerance: 4.272e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Создание полиномиальных фичей\n",
    "poly = PolynomialFeatures(degree=4)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "# Модель Ridge\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge_pipe = make_pipeline(StandardScaler(), PolynomialFeatures(degree=4), Ridge(alpha=1.0))\n",
    "ridge_preds = ridge_pipe.fit(X, y).predict(X)\n",
    "ridge_r2 = r2_score(y, ridge_preds)\n",
    "print(\"Ridge (без Poly): R^2 =\", ridge_r2)\n",
    "\n",
    "# Модель Lasso\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso_pipe = make_pipeline(StandardScaler(), PolynomialFeatures(degree=4), Lasso(alpha=0.1))\n",
    "lasso_preds = lasso_pipe.fit(X, y).predict(X)\n",
    "lasso_r2 = r2_score(y, lasso_preds)\n",
    "print(\"Lasso (без Poly): R^2 =\", lasso_r2)\n",
    "\n",
    "# Модели с использованием PolynomialFeatures\n",
    "ridge_poly = Ridge(alpha=1.0)\n",
    "ridge_poly_pipe = make_pipeline(StandardScaler(), PolynomialFeatures(degree=4), Ridge(alpha=1.0))\n",
    "ridge_poly_preds = ridge_poly_pipe.fit(X_scaled, y).predict(X_scaled)\n",
    "ridge_poly_r2 = r2_score(y, ridge_poly_preds)\n",
    "print(\"Ridge (с Poly): R^2 =\", ridge_poly_r2)\n",
    "\n",
    "lasso_poly = Lasso(alpha=0.1)\n",
    "lasso_poly_pipe = make_pipeline(StandardScaler(), PolynomialFeatures(degree=4), Lasso(alpha=0.1))\n",
    "lasso_poly_preds = lasso_poly_pipe.fit(X_scaled, y).predict(X_scaled)\n",
    "lasso_poly_r2 = r2_score(y, lasso_poly_preds)\n",
    "print(\"Lasso (с Poly): R^2 =\", lasso_poly_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание pipeline с разными методами масштабирования и типами регуляризации\n",
    "scaler_pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures(degree=2, include_bias=False))])\n",
    "minmax_pipe = Pipeline([('scaler', MinMaxScaler()), ('poly', PolynomialFeatures(degree=2, include_bias=False))])\n",
    "\n",
    "ridge_reg_scaled = make_pipeline(scaler_pipe, Ridge())\n",
    "ridge_reg_scaled_minmax = make_pipeline(minmax_pipe, Ridge())\n",
    "\n",
    "lasso_reg_scaled = make_pipeline(scaler_pipe, Lasso())\n",
    "lasso_reg_scaled_minmax = make_pipeline(minmax_pipe, Lasso())\n",
    "\n",
    "# Параметры для поиска\n",
    "param_grid = [{'estimator__alpha': np.logspace(-5, 5, 11)},\n",
    "              {'estimator__alpha': np.logspace(-5, 5, 11), 'estimator__polynomialfeatures__degree': range(1, 4)}]\n",
    "\n",
    "# Настройка GridSearchCV для каждого Pipeline\n",
    "ridge_gridsearch = GridSearchCV(ridge_reg_scaled, param_grid, scoring='r2', cv=5)\n",
    "ridge_gridsearch_minmax = GridSearchCV(ridge_reg_scaled_minmax, param_grid, scoring='r2', cv=5)\n",
    "\n",
    "lasso_gridsearch = GridSearchCV(lasso_reg_scaled, param_grid, scoring='r2', cv=5)\n",
    "lasso_gridsearch_minmax = GridSearchCV(lasso_reg_scaled_minmax, param_grid, scoring='r2', cv=5)\n",
    "\n",
    "# Запуск GridSearchCV для каждого Pipeline\n",
    "ridge_gridsearch.fit(X_train, y_train)\n",
    "ridge_gridsearch_minmax.fit(X_train, y_train)\n",
    "\n",
    "lasso_gridsearch.fit(X_train, y_train)\n",
    "lasso_gridsearch_minmax.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучших моделей и их R2\n",
    "ridge_best_model = ridge_gridsearch.best_estimator_\n",
    "ridge_best_model_minmax = ridge_gridsearch_minmax.best_estimator_\n",
    "ridge_r2 = r2_score(y_test, ridge_best_model.predict(X_test))\n",
    "ridge_r2_minmax = r2_score(y_test, ridge_best_model_minmax.predict(X_test))\n",
    "\n",
    "lasso_best_model = lasso_gridsearch.best_estimator_\n",
    "lasso_best_model_minmax = lasso_gridsearch_minmax.best_estimator_\n",
    "lasso_r2 = r2_score(y_test, lasso_best_model.predict(X_test))\n",
    "lasso_r2_minmax = r2_score(y_test, lasso_best_model_minmax.predict(X_test))\n",
    "\n",
    "# Получение и вывод результатов\n",
    "print(\"Лучшая модель Ridge (масштаб):\")\n",
    "print(\"\\t\", ridge_best_model.get_params())\n",
    "print(\"\\t R2:\", ridge_r2)\n",
    "\n",
    "print(\"Лучшая модель Ridge (MinMaxScale):\")\n",
    "print(\"\\t\", ridge_best_model_minmax.get_params())\n",
    "print(\"\\t R2:\", ridge_r2_minmax)\n",
    "\n",
    "print(\"Лучшая модель Lasso (масштаб):\")\n",
    "print(\"\\t\", lasso_best_model.get_params())\n",
    "print(\"\\t R2:\", lasso_r2)\n",
    "\n",
    "print(\"Лучшая модель Lasso (MinMaxScale):\")\n",
    "print(\"\\t\", lasso_best_model_minmax.get_params())\n",
    "print(\"\\t R2:\", lasso_r2_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  class  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('adult.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Разделите выборку на признаки и целевую переменную(колонка class). Замените целевую переменную на числовые значения ('<=50K' - 1, '>50K' - 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country  \n",
      "0          2174             0              40  United-States  \n",
      "1             0             0              13  United-States  \n",
      "2             0             0              40  United-States  \n",
      "3             0             0              40  United-States  \n",
      "4             0             0              40           Cuba  \n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Замена значений целевой переменной\n",
    "data['class'] = data['class'].replace({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Выделение признаковых и целевых столбцов\n",
    "X = data.drop(['class'], axis=1)\n",
    "y = data['class']\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7607182343065395\n",
      "F1 score: 0.8640999104619929\n"
     ]
    }
   ],
   "source": [
    "# Импорт необходимой функции\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Подготовка предсказаний\n",
    "predicted = y.mode().values[0]\n",
    "predicted = [predicted] * len(y)\n",
    "\n",
    "# Вычисление метрик\n",
    "accuracy = (y == predicted).mean()\n",
    "f1_score = f1_score(y, predicted)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 score:\", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Выясните, присутствуют ли в данных пропуски. Если присутствуют, заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "class             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Определение отсутствующих значений\n",
    "missing_vals = data.isnull()\n",
    "\n",
    "# Создание imputer для заполнения отсутствующих значений\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Применение imputer к данным\n",
    "data_filled = imputer.fit_transform(data)\n",
    "\n",
    "# Преобразование обратно в DataFrame\n",
    "data_filled = pd.DataFrame(data_filled, columns=data.columns)\n",
    "\n",
    "print(data_filled.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Выберите колонки с числовыми и категориальными переменными (используя возможности pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
      "       'hours-per-week'],\n",
      "      dtype='object')\n",
      "Categorical columns: Index(['workclass', 'education', 'marital-status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native-country', 'class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Выбор колонок с числовыми данными\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Выбор колонок с категориальными данными\n",
    "categorical_cols = data.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Создайте пайплайн по обработке числовых и категориальных значений колонок (используйте OneHotEncoder,MinMaxScaler) и посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 600, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1076, in transform\n",
      "    Xs = self._call_func_on_transformers(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 1290, in _transform_one\n",
      "    res = transformer.transform(X, **params.transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1024, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 214, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Holand-Netherlands'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 600, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1076, in transform\n",
      "    Xs = self._call_func_on_transformers(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 1290, in _transform_one\n",
      "    res = transformer.transform(X, **params.transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1024, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 214, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Holand-Netherlands'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 600, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1076, in transform\n",
      "    Xs = self._call_func_on_transformers(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 1290, in _transform_one\n",
      "    res = transformer.transform(X, **params.transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1024, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 214, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Holand-Netherlands'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "\tAccuracy: nan\n",
      "\tF1 macro: nan\n",
      "KNeighborsClassifier:\n",
      "\tAccuracy: nan\n",
      "\tF1 macro: nan\n",
      "LinearSVC:\n",
      "\tAccuracy: nan\n",
      "\tF1 macro: nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "data['class'] = data['class'].replace({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Выделение признаковых и целевых столбцов\n",
    "X = data.drop(['class'], axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Определение столбцов для обработки\n",
    "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "numeric_columns = ['age', 'fnlwgt', 'education-num']\n",
    "\n",
    "# Пайплайн обработки данных\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat_encoder', OneHotEncoder(), categorical_columns),\n",
    "    ('num_scaler', MinMaxScaler(), numeric_columns)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Алгоритмы классификации\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(),\n",
    "    LinearSVC()\n",
    "]\n",
    "\n",
    "# Кросс-валидация\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "scoring = {'accuracy': 'accuracy', 'f1_macro': 'f1_macro'}\n",
    "results = {}\n",
    "for model in models:\n",
    "    results[model.__class__.__name__] = cross_validate(make_pipeline(preprocessor, model), data, data['class'].values, cv=cv, scoring=scoring)\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    accuracy = result['test_accuracy'].mean()\n",
    "    f1_macro = result['test_f1_macro'].mean()\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"\\tAccuracy: {accuracy:.3f}\")\n",
    "    print(f\"\\tF1 macro: {f1_macro:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями, (испольуйте SimpleImputer). Посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 600, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1076, in transform\n",
      "    Xs = self._call_func_on_transformers(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 1290, in _transform_one\n",
      "    res = transformer.transform(X, **params.transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 903, in transform\n",
      "    Xt = transform.transform(Xt, **routed_params[name].transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1578, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 214, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Holand-Netherlands'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 600, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1076, in transform\n",
      "    Xs = self._call_func_on_transformers(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 1290, in _transform_one\n",
      "    res = transformer.transform(X, **params.transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 903, in transform\n",
      "    Xt = transform.transform(Xt, **routed_params[name].transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1578, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 214, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Holand-Netherlands'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 600, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1076, in transform\n",
      "    Xs = self._call_func_on_transformers(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 1290, in _transform_one\n",
      "    res = transformer.transform(X, **params.transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 903, in transform\n",
      "    Xt = transform.transform(Xt, **routed_params[name].transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1578, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 214, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Holand-Netherlands'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "\taccuracy:\t1.000\n",
      "KNeighborsClassifier:\n",
      "\taccuracy:\t0.966\n",
      "LinearSVC:\n",
      "\taccuracy:\t1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Замена значений '?' на самые частые значения\n",
    "data = data.fillna(data.mode().iloc[0])\n",
    "\n",
    "# Выделение числовых и категориальных колонок\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = data.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Пайплайн для числовых колонок\n",
    "num_pipeline = Pipeline([('imputer', SimpleImputer()),\n",
    "                         ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Пайплайн для категориальных колонок\n",
    "cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                         ('encoder', OrdinalEncoder())])\n",
    "\n",
    "# Комбинация пайплайнов\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_pipeline, numeric_cols),\n",
    "                                              ('cat', cat_pipeline, categorical_cols)])\n",
    "\n",
    "# Алгоритмы классификации\n",
    "models = [LogisticRegression(), KNeighborsClassifier(), LinearSVC()]\n",
    "\n",
    "# Кросс-валидационные оценки\n",
    "scores = {}\n",
    "for model in models:\n",
    "    pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                         ('classifier', model)])\n",
    "    \n",
    "    scores[model.__class__.__name__] = cross_val_score(pipeline, data, data['class'],\n",
    "                                                       scoring='accuracy', cv=5)\n",
    "\n",
    "for model_name, scores in scores.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    for metric, score in zip(['accuracy'], scores):\n",
    "        print(f\"\\t{metric}:\\t{score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score по тем же алгоритмам и метрикам, если просто удалить значения '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Выделение числовых и категориальных колонок\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = data.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Пайплайн для числовых колонок\n",
    "num_pipeline = Pipeline([('imputer', SimpleImputer()),\n",
    "                         ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Пайплайн для категориальных колонок\n",
    "cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                         ('encoder', OrdinalEncoder())])\n",
    "\n",
    "# Комбинация пайплайнов\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_pipeline, numeric_cols),\n",
    "                                              ('cat', cat_pipeline, categorical_cols)])\n",
    "\n",
    "# Алгоритмы классификации\n",
    "models = [LogisticRegression(), KNeighborsClassifier(), LinearSVC()]\n",
    "\n",
    "# Кросс-валидационные оценки\n",
    "scores = {}\n",
    "for model in models:\n",
    "    pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                         ('classifier', model)])\n",
    "    \n",
    "    scores[model.__class__.__name__] = cross_val_score(pipeline, data, data['class'],\n",
    "                                                       scoring='f1_macro', cv=5)\n",
    "\n",
    "for model_name, scores in scores.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    for metric, score in zip(['accuracy', 'f1_macro'], scores.mean(axis=0)):\n",
    "        print(f\"\\t{metric}:\\t{score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 16. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier на данных с замененными значениями '?' на самые частые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 600, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1076, in transform\n",
      "    Xs = self._call_func_on_transformers(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 1290, in _transform_one\n",
      "    res = transformer.transform(X, **params.transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 903, in transform\n",
      "    Xt = transform.transform(Xt, **routed_params[name].transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1578, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 214, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Holand-Netherlands'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 600, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1076, in transform\n",
      "    Xs = self._call_func_on_transformers(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 1290, in _transform_one\n",
      "    res = transformer.transform(X, **params.transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 903, in transform\n",
      "    Xt = transform.transform(Xt, **routed_params[name].transform)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1578, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 214, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Holand-Netherlands'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier:\n",
      "\taccuracy:\t1.000\n",
      "GradientBoostingClassifier:\n",
      "\taccuracy:\t1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Замена значений '?' на самые частые значения\n",
    "data = data.fillna(data.mode().iloc[0])\n",
    "\n",
    "# Выделение числовых и категориальных колонок\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = data.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Пайплайн для числовых колонок\n",
    "num_pipeline = Pipeline([('imputer', SimpleImputer()),\n",
    "                         ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Пайплайн для категориальных колонок\n",
    "cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                         ('encoder', OrdinalEncoder())])\n",
    "\n",
    "# Комбинация пайплайнов\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_pipeline, numeric_cols),\n",
    "                                              ('cat', cat_pipeline, categorical_cols)])\n",
    "\n",
    "# Алгоритмы классификации\n",
    "models = [RandomForestClassifier(), GradientBoostingClassifier()]\n",
    "\n",
    "# Кросс-валидационные оценки\n",
    "scores = {}\n",
    "for model in models:\n",
    "    pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                         ('classifier', model)])\n",
    "    \n",
    "    scores[model.__class__.__name__] = cross_val_score(pipeline, data, data['class'],\n",
    "                                                       scoring='accuracy', cv=5)\n",
    "\n",
    "for model_name, scores in scores.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    for metric, score in zip(['accuracy'], scores):\n",
    "        print(f\"\\t{metric}:\\t{score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Выделение числовых и категориальных колонок\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = data.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Пайплайн для числовых колонок\n",
    "num_pipeline = Pipeline([('imputer', SimpleImputer()),\n",
    "                         ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Пайплайн для категориальных колонок\n",
    "cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                         ('encoder', OrdinalEncoder())])\n",
    "\n",
    "# Комбинация пайплайнов\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_pipeline, numeric_cols),\n",
    "                                              ('cat', cat_pipeline, categorical_cols)])\n",
    "# Создание объектов GridSearchCV\n",
    "lr_gridsearch = GridSearchCV(Pipeline([('preprocessor', preprocessor),\n",
    "                                       ('classifier', LogisticRegression())]),\n",
    "                             param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "knn_gridsearch = GridSearchCV(Pipeline([('preprocessor', preprocessor),\n",
    "                                        ('classifier', KNeighborsClassifier())]),\n",
    "                              param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "svc_gridsearch = GridSearchCV(Pipeline([('preprocessor', preprocessor),\n",
    "                                        ('classifier', LinearSVC())]),\n",
    "                              param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "# Запуск GridSearchCV для каждого Pipeline\n",
    "lr_gridsearch.fit(data, data['class'])\n",
    "knn_gridsearch.fit(data, data['class'])\n",
    "svc_gridsearch.fit(data, data['class'])\n",
    "\n",
    "# Получение лучших моделей и их accuracy\n",
    "lr_best_model = lr_gridsearch.best_estimator_\n",
    "knn_best_model = knn_gridsearch.best_estimator_\n",
    "svc_best_model = svc_gridsearch.best_estimator_\n",
    "\n",
    "lr_accuracy = lr_gridsearch.best_score_\n",
    "knn_accuracy = knn_gridsearch.best_score_\n",
    "svc_accuracy = svc_gridsearch.best_score_\n",
    "\n",
    "# Получение F1-Score для лучших моделей\n",
    "lr_f1_score = lr_gridsearch.best_score_\n",
    "knn_f1_score = knn_gridsearch.best_score_\n",
    "svc_f1_score = svc_gridsearch.best_score_\n",
    "\n",
    "\n",
    "print(\"Лучшая модель LogisticRegression:\")\n",
    "print(\"\\t\", lr_best_model.get_params())\n",
    "print(\"\\t Accuracy:\", lr_accuracy)\n",
    "print(\"\\t F1 Score:\", lr_f1_score)\n",
    "\n",
    "print(\"Лучшая модель KNeighborsClassifier:\")\n",
    "print(\"\\t\", knn_best_model.get_params())\n",
    "print(\"\\t Accuracy:\", knn_accuracy)\n",
    "print(\"\\t F1 Score:\", knn_f1_score)\n",
    "\n",
    "print(\"Лучшая модель LinearSVC:\")\n",
    "print(\"\\t\", svc_best_model.get_params())\n",
    "print(\"\\t Accuracy:\", svc_accuracy)\n",
    "print(\"\\t F1 Score:\", svc_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_11148/4278391279.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\110889~1.SIG\\AppData\\Local\\Temp/ipykernel_11148/4278391279.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python -m pip install --upgrade scikit-learn\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -m pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
